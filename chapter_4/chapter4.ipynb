{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONVOLUTIONAL NEURAL NETWORKS(CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter we Will be building object-recogintion dataset and applying several CNN models to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is fundamentally means by which layers are connected in convolutional neural networks.\n",
    "We use the built-n TensorFLow conv2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf.nn.conv2d(x, w, strides=[1,1,1,1], padding ='SAME')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x is the data(input image). Feature map is simply a commonly used term referring to the output of each layer. The output of this operation will depend on the shape of x and W, in this case is four-dimensional. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#[None, 28, 28, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This means that the unknown images of 28 x 28 pixels and with one color channel(since these are grayscale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#[5, 5, 1, 32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weight we use will be of the above shape, where the initial  5x5x5x1 \n",
    "represents the size of the small \"window\" in the image to be convolved, in\n",
    "our case a 5x5 region.\n",
    "The final 32 is the number of feature maps. In other words, we have have multiple sets of weight\n",
    "for convolutional layer.\n",
    "The strides argument controls the spatial movement of the filter W across the\n",
    "image(or feature map) x.\n",
    "The value [1,1,1,1] means that the filter is applied to the input in one-pixel intervals\n",
    "in each dimension, corresponding to a 'full' convolution.\n",
    "Finally, the setting padding to \"SAME\" means that the borders of x padded such that\n",
    "the size of the result of the operation is the same as the size of x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
