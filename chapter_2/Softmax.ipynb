{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1 : Softmax Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load tensorflow package\n",
    "import tensorflow as tf\n",
    "\n",
    "#import MNIST dataset \n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize of some parameters: dataset name, Number of step, and Minibatch size.\n",
    "DATA_DIR = \"/tmp/data\"\n",
    "NUM_STEPS = 1000\n",
    "MINIBATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The read_data_sets() method of the MNIST reading utility downloads the dataset\n",
    "saves it locally, setting the stage for further use later in the program. The first\n",
    "argument, DATA_DIR, is the location we wish the data to be saved to locally. We set this\n",
    "to '/tmp/data', but any other location would be just as good. The second argument\n",
    "tells the utility how we want the data to be labeled; one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data\\train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "data = input_data.read_data_sets(DATA_DIR, one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The image itself (x) is a placeholder,\n",
    "because it will be supplied by us when running the computation graph. The size\n",
    "[None, 784] means that each image is of size 784 (28×28 pixels unrolled into a single\n",
    "vector), and None is an indicator that we are not currently specifying how many of\n",
    "these images we will use at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "\n",
    "y_true = tf.placeholder(tf.float32,[None, 10])\n",
    "y_pred = tf.matmul(x, W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The measure of similarity we choose for this model is what is known as cross entropy\n",
    "—a natural choice when the model outputs class probabilities. This element is often\n",
    "referred to as the loss function.  The final piece of the model is how we are going to train it (i.e., how we are going to\n",
    "minimize the loss function). A very common approach is to use gradient descent\n",
    "optimization. Here, 0.5 is the learning rate, controlling how fast our gradient descent\n",
    "optimizer shifts model weights to reduce overall loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 91.06%.\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y_true))\n",
    "\n",
    "\n",
    "\n",
    "gd_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "correct_mask = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_mask, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Train\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for _ in range(NUM_STEPS):\n",
    "        batch_xs, batch_ys = data.train.next_batch(MINIBATCH_SIZE)\n",
    "        sess.run(gd_step, feed_dict ={x: batch_xs, y_true: batch_ys})\n",
    "        \n",
    "        \n",
    "    # Test\n",
    "    \n",
    "    ans = sess.run(accuracy, feed_dict = {x: data.test.images, y_true: data.test.labels})\n",
    "    \n",
    "print(\"Accuracy : {:.4}%.\".format(ans*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
